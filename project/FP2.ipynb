{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea960e6f-e814-4502-b053-c61dc9f0fb55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.2285 - loss: 1.9568 - val_accuracy: 0.4333 - val_loss: 1.4739\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 823ms/step - accuracy: 0.4062 - loss: 1.5515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4062 - loss: 1.5515 - val_accuracy: 0.6087 - val_loss: 1.3323\n",
      "Epoch 3/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.4001 - loss: 1.4937 - val_accuracy: 0.4875 - val_loss: 1.3216\n",
      "Epoch 4/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3750 - loss: 1.3337 - val_accuracy: 0.6087 - val_loss: 1.0401\n",
      "Epoch 5/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.4543 - loss: 1.3549 - val_accuracy: 0.4979 - val_loss: 1.2396\n",
      "Epoch 6/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5312 - loss: 1.1558 - val_accuracy: 0.5652 - val_loss: 1.2712\n",
      "Epoch 7/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.4903 - loss: 1.3032 - val_accuracy: 0.5625 - val_loss: 1.1858\n",
      "Epoch 8/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 1.1834 - val_accuracy: 0.5652 - val_loss: 1.2539\n",
      "Epoch 9/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.5116 - loss: 1.2224 - val_accuracy: 0.5604 - val_loss: 1.1033\n",
      "Epoch 10/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4062 - loss: 1.4027 - val_accuracy: 0.5217 - val_loss: 1.3487\n",
      "Epoch 11/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.5592 - loss: 1.1466 - val_accuracy: 0.6042 - val_loss: 1.0864\n",
      "Epoch 12/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3750 - loss: 1.2202 - val_accuracy: 0.6087 - val_loss: 1.1718\n",
      "Epoch 13/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.5951 - loss: 1.0991 - val_accuracy: 0.6062 - val_loss: 1.0559\n",
      "Epoch 14/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5312 - loss: 0.9784 - val_accuracy: 0.4783 - val_loss: 1.2894\n",
      "Epoch 15/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6235 - loss: 1.0012 - val_accuracy: 0.6083 - val_loss: 1.0441\n",
      "Epoch 16/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 1.0952 - val_accuracy: 0.5217 - val_loss: 1.1074\n",
      "Epoch 17/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6286 - loss: 0.9947 - val_accuracy: 0.5833 - val_loss: 1.0269\n",
      "Epoch 18/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7500 - loss: 0.8040 - val_accuracy: 0.5652 - val_loss: 0.9814\n",
      "Epoch 19/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.6314 - loss: 0.9742 - val_accuracy: 0.6500 - val_loss: 0.9820\n",
      "Epoch 20/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5000 - loss: 1.1503 - val_accuracy: 0.7826 - val_loss: 0.8352\n",
      "Epoch 21/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6441 - loss: 0.9311 - val_accuracy: 0.6292 - val_loss: 0.9904\n",
      "Epoch 22/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.8407 - val_accuracy: 0.6522 - val_loss: 0.9735\n",
      "Epoch 23/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.6520 - loss: 0.9712 - val_accuracy: 0.6146 - val_loss: 0.9880\n",
      "Epoch 24/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7812 - loss: 0.7765 - val_accuracy: 0.6087 - val_loss: 0.7849\n",
      "Epoch 25/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.6648 - loss: 0.9052 - val_accuracy: 0.5979 - val_loss: 1.0203\n",
      "Epoch 26/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.9360 - val_accuracy: 0.6957 - val_loss: 0.8529\n",
      "Epoch 27/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.6763 - loss: 0.8645 - val_accuracy: 0.6125 - val_loss: 0.9958\n",
      "Epoch 28/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5312 - loss: 1.1963 - val_accuracy: 0.5652 - val_loss: 1.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.7025 - loss: 0.8403 - val_accuracy: 0.6271 - val_loss: 0.9877\n",
      "Epoch 30/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7812 - loss: 0.8173 - val_accuracy: 0.5652 - val_loss: 1.4815\n",
      "Epoch 31/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.6724 - loss: 0.8707 - val_accuracy: 0.6229 - val_loss: 0.9697\n",
      "Epoch 32/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5938 - loss: 0.8999 - val_accuracy: 0.5217 - val_loss: 1.0885\n",
      "Epoch 33/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.6590 - loss: 0.8856 - val_accuracy: 0.6250 - val_loss: 0.9741\n",
      "Epoch 34/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5938 - loss: 0.9735 - val_accuracy: 0.6087 - val_loss: 1.0221\n",
      "Epoch 35/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.6881 - loss: 0.8650 - val_accuracy: 0.6354 - val_loss: 0.9514\n",
      "Epoch 36/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 1.0443 - val_accuracy: 0.6957 - val_loss: 0.8398\n",
      "Epoch 37/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.6884 - loss: 0.8399 - val_accuracy: 0.6479 - val_loss: 0.9674\n",
      "Epoch 38/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.6888 - val_accuracy: 0.6957 - val_loss: 0.7094\n",
      "Epoch 39/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.7182 - loss: 0.7943 - val_accuracy: 0.6333 - val_loss: 0.9120\n",
      "Epoch 40/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.6190 - val_accuracy: 0.6087 - val_loss: 1.0455\n",
      "Epoch 41/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.6937 - loss: 0.8050 - val_accuracy: 0.6396 - val_loss: 0.9703\n",
      "Epoch 42/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7812 - loss: 0.6219 - val_accuracy: 0.6522 - val_loss: 0.9785\n",
      "Epoch 43/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.7199 - loss: 0.7502 - val_accuracy: 0.6333 - val_loss: 0.9344\n",
      "Epoch 44/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8438 - loss: 0.7177 - val_accuracy: 0.6087 - val_loss: 1.2547\n",
      "Epoch 45/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7029 - loss: 0.8286 - val_accuracy: 0.6417 - val_loss: 0.9526\n",
      "Epoch 46/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7188 - loss: 0.8023 - val_accuracy: 0.6087 - val_loss: 0.7703\n",
      "Epoch 47/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7171 - loss: 0.7453 - val_accuracy: 0.6417 - val_loss: 0.9185\n",
      "Epoch 48/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.6938 - val_accuracy: 0.4783 - val_loss: 1.0063\n",
      "Epoch 49/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6984 - loss: 0.7905 - val_accuracy: 0.6333 - val_loss: 0.9418\n",
      "Epoch 50/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.8711 - val_accuracy: 0.5217 - val_loss: 1.2112\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[11 27 10 20 12  0]\n",
      " [18 21 14 31 16  0]\n",
      " [11 24 15 20 10  2]\n",
      " [23 24 20 32 18  1]\n",
      " [20 33 18 14  7  4]\n",
      " [ 8  4  5  7  3  0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cardboard       0.12      0.14      0.13        80\n",
      "       glass       0.16      0.21      0.18       100\n",
      "       metal       0.18      0.18      0.18        82\n",
      "       paper       0.26      0.27      0.26       118\n",
      "     plastic       0.11      0.07      0.09        96\n",
      "       trash       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.17       503\n",
      "   macro avg       0.14      0.15      0.14       503\n",
      "weighted avg       0.16      0.17      0.16       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import Label\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "# 設置數據集路徑\n",
    "base_dir = r'C:\\dataFINAL\\archive\\Garbage classification\\Garbage classification'\n",
    "train_dir = base_dir\n",
    "validation_dir = base_dir  # 假設數據集沒有分為訓練和驗證集，使用同一個目錄\n",
    "\n",
    "# 圖像數據生成器和數據增強\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 使用 20% 數據作為驗證集\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# 使用預訓練模型 VGG16\n",
    "base_model = tf.keras.applications.VGG16(include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# 鎖定預訓練模型的權重\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 模型構建\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # 假設有6個分類\n",
    "])\n",
    "    \n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 模型訓練\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=50  # 增加訓練次數\n",
    ")\n",
    "\n",
    "# 模型評估\n",
    "validation_generator.reset()\n",
    "Y_pred = model.predict(validation_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(validation_generator.class_indices.keys())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "# 保存模型\n",
    "model.save('garbage_classification_model_vgg16.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaab54e-e80a-40ca-8cbd-20fd80bd5f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Frame, Button\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 讀取模型\n",
    "model = tf.keras.models.load_model('garbage_classification_model_vgg16.h5')\n",
    "target_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "# 創建主窗口\n",
    "root = tk.Tk()\n",
    "root.title(\"垃圾分類系統\")\n",
    "root.geometry(\"600x400\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# 標題\n",
    "title_label = tk.Label(root, text=\"垃圾分類系統\", font=(\"Helvetica\", 24, \"bold\"), bg=\"#f0f0f0\")\n",
    "title_label.pack(pady=20)\n",
    "\n",
    "# 上傳圖片框架\n",
    "frame = Frame(root, bg=\"#f0f0f0\")\n",
    "frame.pack(pady=10)\n",
    "\n",
    "# 圖片顯示區域\n",
    "img_label = Label(frame, bg=\"#f0f0f0\")\n",
    "img_label.pack(pady=10)\n",
    "\n",
    "# 上傳按鈕\n",
    "upload_button = Button(frame, text=\"上傳圖片\", command=lambda: upload_image(frame), font=(\"Helvetica\", 14), bg=\"#4CAF50\", fg=\"white\")\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "# 結果顯示標籤\n",
    "result_label = Label(root, text=\"\", font=(\"Helvetica\", 16), bg=\"#f0f0f0\")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "def upload_image(frame):\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    uploaded = Image.open(file_path)\n",
    "    uploaded.thumbnail((150, 150))\n",
    "    img = ImageTk.PhotoImage(uploaded)\n",
    "    img_label.config(image=img)\n",
    "    img_label.image = img\n",
    "\n",
    "    img_array = np.array(uploaded.resize((150, 150))) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = target_names[np.argmax(prediction)]\n",
    "    result_label.config(text=f\"分類結果: {predicted_class}\", fg=\"#333\")\n",
    "\n",
    "# 版權信息\n",
    "footer_label = Label(root, text=\"© 2024 垃圾分類系統\", font=(\"Helvetica\", 10), bg=\"#f0f0f0\", fg=\"#888\")\n",
    "footer_label.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81330758-b56b-40ad-a532-8381ee22fd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
